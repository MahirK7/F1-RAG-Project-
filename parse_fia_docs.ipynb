{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95712540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No PDFs found at data/raw/australia_2025/*.pdf. Please check the folder and file names.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Parse FIA Docs (Australia 2025)\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Settings ---\n",
    "RACE = \"australia_2025\"\n",
    "RAW_DIR = os.path.join(\"data\", \"raw\", RACE)\n",
    "OUTPUT_DIR = \"processed\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, f\"fia_docs_{RACE}.txt\")\n",
    "\n",
    "# --- Find PDFs (case-insensitive) ---\n",
    "pdf_files = glob.glob(os.path.join(RAW_DIR, \"*.pdf\")) + glob.glob(os.path.join(RAW_DIR, \"*.PDF\"))\n",
    "\n",
    "print(f\"Looking for PDFs in: {os.path.abspath(RAW_DIR)}\")\n",
    "if not pdf_files:\n",
    "    print(\"⚠️ No PDFs found. Creating an empty output file.\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\")\n",
    "    print(f\"✅ Empty file created at {OUTPUT_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load PDFs ---\n",
    "docs = []\n",
    "for pdf in pdf_files:\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        loaded = loader.load()\n",
    "        docs.extend(loaded)\n",
    "        print(f\"Loaded {len(loaded)} docs from {os.path.basename(pdf)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not load {pdf}: {e}\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(docs)}\")\n",
    "\n",
    "# --- Split into chunks ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "print(f\"Total chunks created: {len(split_docs)}\")\n",
    "\n",
    "# --- Preview ---\n",
    "if split_docs:\n",
    "    print(\"\\nExample chunk:\\n\", split_docs[0].page_content[:500])\n",
    "\n",
    "# --- Save chunks to txt ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for d in split_docs:\n",
    "        f.write(d.page_content.strip() + \"\\n\\n\")\n",
    "\n",
    "print(f\"✅ FIA docs exported to {OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
